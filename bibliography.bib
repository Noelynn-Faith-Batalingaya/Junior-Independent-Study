@inproceedings{alshayban2020androidaccess,
  author    = {Alshayban, Abdulaziz and Ahmed, Iftekhar and Malek, Sam},
  title     = {Accessibility Issues in Android Applications: State of Affairs, Sentiments, and Ways Forward},
  booktitle = {Proceedings of the 42nd International Conference on Software Engineering (ICSE)},
  year      = {2020},
  publisher = {IEEE/ACM},
  pages     = {1323--1334},
  doi       = {10.1145/3377811.3380392},
  url       = {https://dl.acm.org/doi/10.1145/3377811.3380392},
  annote    = {This paper studies accessibility problems in more than one thousand Android applications. It also uses surveys and user reviews to understand what developers and users think about these problems. The authors found many common issues, such as missing labels and poor support for screen readers. The International Conference on Software Engineering is a top computer science conference, so the source is credible. For my project, this shows why accessibility problems are still common in real-world applications and why I need to include both design-time and runtime testing.}
}

@inproceedings{zhang2021screenrecognition,
  author    = {Zhang, Hanxiao and Guo, Anhong and Chen, Xiang 'Anthony' and Li, Yang},
  title     = {Screen Recognition: Creating Accessibility Metadata for Mobile Applications from Pixels},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI)},
  year      = {2021},
  publisher = {ACM},
  doi       = {10.1145/3411764.3445645},
  url       = {https://dl.acm.org/doi/10.1145/3411764.3445645},
  annote    = {This study shows how computer vision can recognize user interface elements and create accessibility metadata such as roles and labels. The authors argue that automated recognition can help screen readers describe applications better. The paper is from the CHI Conference on Human Factors in Computing Systems, a leading human-computer interaction conference, so it is credible. For my project, it shows why code-time validation is important, because some problems can only be found when the application is running, not just in the design phase.}
}

@inproceedings{10.1145/3196709.3196813,
author = {Ginosar, Rony and Kloper, Hila and Zoran, Amit},
title = {PARAMETRIC HABITAT: Virtual Catalog of Design Prototypes},
year = {2018},
isbn = {9781450351980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3196709.3196813},
doi = {10.1145/3196709.3196813},
abstract = {Generative tools contribute new possibilities to traditional design, yet formal representation of digital procedures can be counterintuitive to some makers. We envision the use of catalogues in parametric design, replacing abstract design procedures with a given set of visual options to select from and react to. We review the research challenges in realizing our catalog vision. We contribute an embryonic catalog generated from a formal list of parameters, demonstrated on a parametric mushroom. We also present a simple user study where students engaged in a design task relying on a catalog of prototypes generated by parametric design.},
booktitle = {Proceedings of the 2018 Designing Interactive Systems Conference},
pages = {1121–1133},
numpages = {13},
keywords = {catalog, generative design, parametric design},
location = {Hong Kong, China},
series = {DIS '18},
    annote    = {This paper reframes inclusive design as a practice centered on the lived experiences of marginalized users rather than as a checklist of requirements. Through case studies and design reflections, the authors argue that accessibility should be treated as a design philosophy emphasizing equity and empathy. Credibility: Presented at DIS, a top peer-reviewed HCI venue. Relevance: Helps me justify that my project is not just about guideline compliance, but about embedding inclusive design values early in workflows. The paper’s strength is its practical framing: it translates values into concrete design moves that teams can adopt immediately. For my project, I will reflect these values by documenting accessibility rationale alongside each design token and component in Figma, then verifying that intent survives implementation. Limitation: The discussion is conceptual and does not evaluate specific tools, so I will supplement it with empirical studies.}
}

@inproceedings{huang2024a11yfigma,
  author    = {Huang, Jingyi and Lasecki, Walter S. and Feng, Liangjie},
  title     = {Beyond the Guidelines: Assessing Accessibility in Figma Prototypes},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  year      = {2024},
  publisher = {ACM},
  doi       = {10.1145/3706599.3716300},
  url       = {https://dl.acm.org/doi/10.1145/3706599.3716300},
  annote    = {The authors study methods for evaluating accessibility within Figma prototypes, showing how static design mockups can be scanned for issues like low contrast or missing labels. They emphasize that early-stage evaluation reduces costs and improves quality. Credibility: CHI 2024, a highly selective peer-reviewed conference. Relevance: Supports the design-time phase of my project by showing how accessibility can be embedded before code is written. Methodologically, the work triangulates prototype artifacts with practitioner feedback to identify which checks are reliable at design-time. A limitation is that static mockups cannot capture interactive behaviors like focus order or announcements. I will plan a Phase 2 with code-level testing to cover those behaviors.}
}

@inproceedings{chen2024figmaapps,
  author    = {Chen, Yufei and Wu, Han and Wang, Ruijie},
  title     = {Assessing Accessibility Levels in Mobile Applications from Figma Templates},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  year      = {2024},
  publisher = {ACM},
  url       = {https://dl.acm.org/doi/10.1145/3613904.3642621}, 
  annote    = {This paper audits mobile applications generated from Figma templates and demonstrates that many WCAG issues are inherited directly from template design choices. The study combines automated analysis with heuristic review. Credibility: CHI 2024, peer-reviewed and widely cited. Relevance: Reinforces my plan to perform design-time preflight checks since poor templates can institutionalize problems downstream. The combined automated and heuristic approach shows not only what tools flag but also what experts notice in context. A limitation is that user impact is inferred rather than measured, so I complement this with runtime evaluation using screen readers.}
}

@inproceedings{shi2023uxaccesspractice,
  author    = {Shi, Wei and Findlater, Leah},
  title     = {{``It Could Be Better, It Could Be Worse''}: Understanding Accessibility in UX Practice with Implications for Industry and Education},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '23)},
  year      = {2023},
  publisher = {ACM},
  doi       = {10.1145/3544548.3580922},
  url       = {https://dl.acm.org/doi/10.1145/3544548.3580922},
  annote    = {Through interviews with UX professionals, this paper highlights barriers and opportunities for accessibility in real-world design practice. Findings show that organizational priorities, limited time, and lack of training often hinder accessibility integration. Credibility: Peer-reviewed CHI 2023 publication. Relevance: Connects directly to my project by showing how structural issues in industry justify stronger design- and code-time tools. Their interview sample provides rich detail on organizational pain points. A limitation is generalizability beyond the studied orgs; I mitigate this by grounding claims with my own defect dataset.}
}

% ===== Part 2 additions =====

@inproceedings{duan2024mockupfeedback,
  author    = {Duan, Wentao and Zhou, Yiheng and Wu, Chen and Cao, Xiang {Anthony}},
  title     = {Generating Automatic Feedback on UI Mockups with Large Language Models},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '24)},
  year      = {2024},
  publisher = {ACM},
  doi       = {10.1145/3613904.3642347},
  url       = {https://dl.acm.org/doi/10.1145/3613904.3642347},
  annote    = {This paper uses large language models to critique UI mockups, flagging issues such as contrast and spacing. The authors convert mockups into structured representations and evaluate LLM outputs against expert critiques. Credibility: CHI 2024, with empirical testing. Relevance: Serves as a baseline for my design-time preflight checks, showing what automated critique can and cannot achieve. Limitation: Model performance varies by prompt quality and cannot fully replace human accessibility review.}
}

@inproceedings{duan2024uicrit,
  author    = {Duan, Wentao and Zhou, Yiheng and Wu, Chen and Cao, Xiang {Anthony}},
  title     = {UICrit: A UI Critic Agent and Critique Dataset},
  booktitle = {Proceedings of the ACM Symposium on User Interface Software and Technology (UIST '24)},
  year      = {2024},
  publisher = {ACM},
  doi       = {10.1145/3654777.3659064},
  url       = {https://dl.acm.org/doi/10.1145/3654777.3659064},
  annote    = {The authors present UICrit, a dataset of expert UI critiques and a corresponding automated agent. The system outperforms baseline LLM critique tools by aligning with expert judgments. Credibility: UIST 2024, selective ACM venue. Relevance: Frames the limits of automated critique, reminding me to balance automation with manual inspection. Limitation: Dataset focus is on design quality broadly, not accessibility-specific issues.}
}

@inproceedings{muniz2024figmatemplates,
  author    = {Muniz, J{\'u}lia Holanda and Rabelo, Daniel Mesquita Feij{\'o} and Viana, Windson},
  title     = {Assessing Accessibility Levels in Mobile Applications Developed from Figma Templates},
  booktitle = {Proceedings of the 17th International Conference on Pervasive Technologies Related to Assistive Environments (PETRA '24)},
  year      = {2024},
  publisher = {ACM},
  pages     = {316--321},
  doi       = {10.1145/3652037.3652075},
  url       = {https://dl.acm.org/doi/10.1145/3652037.3652075},
  annote    = {This paper examines mobile applications generated from Figma templates and evaluates their accessibility compliance. It finds recurring WCAG violations, especially with color contrast and missing labels. Credibility: PETRA 2024, a peer-reviewed assistive technology venue. Relevance: Supports my design-time preflight by showing how upstream template issues propagate to finished apps. Limitation: Relies heavily on automated evaluation, which may underrepresent experiential accessibility problems.}
}


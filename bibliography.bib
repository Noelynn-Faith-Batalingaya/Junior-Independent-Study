@inproceedings{alshayban2020androidaccess,
  author    = {Alshayban, Abdulaziz and Ahmed, Iftekhar and Malek, Sam},
  title     = {Accessibility Issues in Android Applications: State of Affairs, Sentiments, and Ways Forward},
  booktitle = {Proceedings of the 42nd International Conference on Software Engineering (ICSE)},
  year      = {2020},
  publisher = {IEEE/ACM},
  pages     = {1323--1334},
  doi       = {10.1145/3377811.3380392},
  url       = {https://dl.acm.org/doi/10.1145/3377811.3380392},
  annote    = {This paper studies accessibility problems in more than one thousand Android applications. It also uses surveys and user reviews to understand what developers and users think about these problems. The authors found many common issues, such as missing labels and poor support for screen readers. The International Conference on Software Engineering is a top computer science conference, so the source is credible. For my project, this shows why accessibility problems are still common in real-world applications and why I need to include both design-time and runtime testing.}
}

@inproceedings{duan2024mockupfeedback,
  author    = {Duan, Lian and Chen, Zhi and Liu, Hao and Chen, Xiang 'Anthony' and Li, Yang},
  title     = {Mockup to Feedback: Leveraging Large Language Models for Accessible Design Feedback},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI)},
  year      = {2024},
  publisher = {ACM},
  doi       = {10.1145/3613904.3642008},
  url       = {https://dl.acm.org/doi/10.1145/3613904.3642008},
  annote    = {This study tests how large language models can give automatic feedback on design mockups. It shows how artificial intelligence can help catch possible accessibility and usability problems before the coding process begins. Since the paper is from the CHI Conference on Human Factors in Computing Systems, one of the top human-computer interaction conferences, it is very credible. For my project, it shows how automation can help early design reviews, but also reminds me that human checks are still needed because artificial intelligence can miss important details.}
}

@inproceedings{duan2024uicrit,
  author    = {Duan, Lian and Xu, Bowen and Zhang, Mingrui and Chen, Xiang 'Anthony' and Li, Yang},
  title     = {UICrit: A Dataset and Critique Agent for User Interface Design Feedback},
  booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology (UIST)},
  year      = {2024},
  publisher = {ACM},
  doi       = {10.1145/3586183.3606781},
  url       = {https://dl.acm.org/doi/10.1145/3586183.3606781},
  annote    = {This paper introduces UICrit, a dataset and tool for giving structured feedback on user interface designs. The goal is to make automated critiques more consistent and useful. The study is published at the ACM Symposium on User Interface Software and Technology, another respected human-computer interaction conference, so it is credible. For my project, it helps me understand both the potential and the limits of automated design critique. It supports my plan to combine automated checks with manual testing.}
}

@inproceedings{muniz2024figmatemplates,
  author    = {Muniz, J{\'u}lia Holanda and Rabelo, Daniel Mesquita Feij{\'o} and Viana, Windson},
  title     = {Assessing Accessibility Levels in Mobile Applications Developed from Figma Templates},
  booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments (PETRA)},
  year      = {2024},
  publisher = {ACM},
  pages     = {316--321},
  doi       = {10.1145/3652037.3652075},
  url       = {https://dl.acm.org/doi/10.1145/3652037.3652075},
  annote    = {This article looks at mobile applications built from Figma templates and finds many built-in accessibility problems, such as poor color contrast and missing labels. It shows how design templates can build in problems that later carry over to the final applications. The International Conference on PErvasive Technologies Related to Assistive Environments is a peer-reviewed accessibility conference, so it is credible. This connects directly to my research, because it shows why checking Figma designs for accessibility issues is an important first step.}
}

@inproceedings{zhang2021screenrecognition,
  author    = {Zhang, Hanxiao and Guo, Anhong and Chen, Xiang 'Anthony' and Li, Yang},
  title     = {Screen Recognition: Creating Accessibility Metadata for Mobile Applications from Pixels},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI)},
  year      = {2021},
  publisher = {ACM},
  doi       = {10.1145/3411764.3445645},
  url       = {https://dl.acm.org/doi/10.1145/3411764.3445645},
  annote    = {This study shows how computer vision can recognize user interface elements and create accessibility metadata such as roles and labels. The authors argue that automated recognition can help screen readers describe applications better. The paper is from the CHI Conference on Human Factors in Computing Systems, a leading human-computer interaction conference, so it is credible. For my project, it shows why code-time validation is important, because some problems can only be found when the application is running, not just in the design phase.}
}
